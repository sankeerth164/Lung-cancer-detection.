# -*- coding: utf-8 -*-
"""Mini_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sFHnbU6zydxZKJopJkrYn1sgRtemeI-5
"""

!pip install kaggle

from google.colab import files
files.upload()  # Upload kaggle.json here

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d andrewmvd/lung-and-colon-cancer-histopathological-images -p /content/

!unzip /content/lung-and-colon-cancer-histopathological-images.zip -d /content/lung_and_colon_cancer_data

!pip install numpy pandas matplotlib seaborn scikit-learn opencv-python

import os

dataset_path = '/content/lung_and_colon_cancer_data'
if os.path.exists(dataset_path):
    print("Dataset Path Found!")
    for root, dirs, files in os.walk(dataset_path):
        print(f"Directory: {root}")
        print(f"Subdirectories: {dirs}")
        print(f"Number of images: {len(files)}")
        print('-' * 30)
else:
    print("Dataset path not found. Please check the extraction path.")

import os

dataset_path = '/content/lung_and_colon_cancer_data/lung_colon_image_set'

def search_for_folders(path):
    for root, dirs, files in os.walk(path):
        if 'lung' in root.lower() or 'colon' in root.lower():
            print(f"Found Folder: {root}")

search_for_folders(dataset_path)

!find /content -type d -name "*lung*"

folder_path = '/content/lung_and_colon_cancer_data/lung_colon_image_set/lung_n'
print("Folder exists:", os.path.exists(folder_path))

import os
import matplotlib.pyplot as plt
import cv2

# Correct dataset path
dataset_path = '/content/lung_and_colon_cancer_data/lung_colon_image_set'

# Class folders (Lung + Colon)
classes = {
    'lung_image_sets/lung_n': 'Lung - Normal',
    'lung_image_sets/lung_aca': 'Lung - Adenocarcinoma',
    'lung_image_sets/lung_scc': 'Lung - Squamous Cell Carcinoma',
    'colon_image_sets/colon_n': 'Colon - Normal',
    'colon_image_sets/colon_aca': 'Colon - Adenocarcinoma'
}

# Plot images
plt.figure(figsize=(9, 7))

for i, (folder, label) in enumerate(classes.items(), 1):
    folder_path = os.path.join(dataset_path, folder)

    if os.path.exists(folder_path):
        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpeg', '.jpg', '.png'))]

        if image_files:
            img_path = os.path.join(folder_path, image_files[0])
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            plt.subplot(2, 3, i)
            plt.imshow(img)
            plt.title(label)
            plt.axis('off')
        else:
            print(f"No images found in {folder_path}")
    else:
        print(f"Folder not found: {folder_path}")

plt.tight_layout()
plt.show()

!pip install numpy pandas opencv-python matplotlib seaborn
!pip install tensorflow numpy pandas matplotlib seaborn

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Parameters
img_size = 224
batch_size = 32

# Data paths
train_data_dir = '/content/lung_and_colon_cancer_data/lung_colon_image_set/lung_image_sets'

# Data Generator with Preprocessing
datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,
    validation_split=0.2  # 80% train, 20% validation
)

# Train and Validation Data
train_generator = datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='sparse',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode='sparse',
    subset='validation'
)

print("Data loading complete!")

!pip install tensorflow

""" CNN Model Code"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the CNN model
model = keras.Sequential([
    # Convolutional layers
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),

    # Flatten layer
    layers.Flatten(),

    # Fully connected layers
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),  # Prevent overfitting
    layers.Dense(3, activation='softmax')  # 3 Classes
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Summary of the model
model.summary()

"""Training Code"""

# Define callbacks to monitor training
early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(
    train_generator,
    epochs=30,
    validation_data=val_generator,
    callbacks=[early_stopping]
)

# Evaluate on validation data
val_loss, val_accuracy = model.evaluate(val_generator)

print(f"Validation Accuracy: {val_accuracy*100:.2f}%")
print(f"Validation Loss: {val_loss:.4f}")

import matplotlib.pyplot as plt

# Plot Accuracy
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')

plt.tight_layout()
plt.show()

import random
import os
import matplotlib.pyplot as plt
import cv2

# Path to dataset
base_path = '/content/lung_and_colon_cancer_data/lung_colon_image_set/lung_image_sets'

# Collect all images from all subfolders
all_images = []
for class_folder in os.listdir(base_path):
    class_path = os.path.join(base_path, class_folder)
    if os.path.isdir(class_path):
        images = [os.path.join(class_path, img) for img in os.listdir(class_path)]
        all_images.extend(images)

# Randomly select 5 images from the entire dataset
sample_images = random.sample(all_images, 5)

# Display the images
plt.figure(figsize=(10, 5))
for i, img_path in enumerate(sample_images):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.subplot(1, 5, i+1)
    plt.imshow(img)
    plt.axis('off')
    plt.title("Random Image")
plt.tight_layout()
plt.show()

import cv2
import numpy as np

# Preprocessing Function
def preprocess_image(image_path):
    try:
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (224, 224))  # Resize to match the model input
        img = img / 255.0  # Normalize
        img = np.expand_dims(img, axis=0)  # Add batch dimension
        return img
    except Exception as e:
        print(f"Error in preprocessing: {e}")
        return None

def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (224, 224))  # Resize to match model input
    img = img / 255.0  # Normalize
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    return img

def predict_image(image_path):
    img = preprocess_image(image_path)
    prediction = model.predict(img)
    class_names = ['Normal', 'Adenocarcinoma', 'Squamous Cell Carcinoma']
    predicted_class = class_names[np.argmax(prediction)]
    confidence = np.max(prediction) * 100
    print(f"Prediction: {predicted_class} with {confidence:.2f}% confidence.")

# Perform predictions on the selected random images
for img_path in sample_images:
    print(f"Image Path: {img_path}")
    predict_image(img_path)

"""Add Class Weights to Training"""

for class_folder in os.listdir(base_path):
    class_path = os.path.join(base_path, class_folder)
    num_images = len(os.listdir(class_path))
    print(f"Class: {class_folder}, Number of Images: {num_images}")

from sklearn.utils.class_weight import compute_class_weight
import numpy as np

class_names = ['Normal', 'Adenocarcinoma', 'Squamous Cell Carcinoma']
class_counts = [5000, 5000, 5000]  # Update based on actual numbers
class_weights = compute_class_weight('balanced', classes=np.unique(class_names), y=class_names)

# Convert to dictionary
class_weight_dict = dict(enumerate(class_weights))
print("Class Weights:", class_weight_dict)

# Add class weights to model.fit
history = model.fit(
    train_generator,
    epochs=30,
    validation_data=val_generator,
    class_weight=class_weight_dict,
    callbacks=[early_stopping]
)

import os

# Path to dataset
base_path = '/content/lung_and_colon_cancer_data/lung_colon_image_set/lung_image_sets'

# Check class distribution
for class_folder in os.listdir(base_path):
    class_path = os.path.join(base_path, class_folder)
    if os.path.isdir(class_path):
        num_images = len(os.listdir(class_path))
        print(f"Class: {class_folder}, Number of Images: {num_images}")

"""Apply Class Weights and Retrain"""

from sklearn.utils.class_weight import compute_class_weight
import numpy as np

# Define class labels
class_labels = ['Normal', 'Adenocarcinoma', 'Squamous Cell Carcinoma']

# Calculate class weights
class_weight = compute_class_weight('balanced', classes=np.array([0, 1, 2]), y=[0]*5000 + [1]*5000 + [2]*5000)
class_weight_dict = {i: weight for i, weight in enumerate(class_weight)}

print("Class Weights:", class_weight_dict)

# Define callbacks to monitor training
early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Retrain the model with class weights
history = model.fit(
    train_generator,
    epochs=30,
    validation_data=val_generator,
    class_weight=class_weight_dict,
    callbacks=[early_stopping]
)

""" Evaluate on Validation Data"""

val_loss, val_accuracy = model.evaluate(val_generator)
print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

"""Generate a Classification Report"""

from sklearn.metrics import classification_report
import numpy as np

# Predict on validation data
y_true = val_generator.classes
y_pred = np.argmax(model.predict(val_generator), axis=1)

# Class names
class_names = ['Normal', 'Adenocarcinoma', 'Squamous Cell Carcinoma']

# Get classification report as a dictionary
report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)

# Print only the F1-scores
print("F1 Scores:")
for class_name in class_names:
    print(f"{class_name}: {report[class_name]['f1-score']:.4f}")

import matplotlib.pyplot as plt

# Plot accuracy
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()

# Plot loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')
plt.show()

"""Picking Random Images from the Entire Dataset"""

import random
import os
import cv2
import matplotlib.pyplot as plt

# Path to dataset
base_path = '/content/lung_and_colon_cancer_data/lung_colon_image_set/lung_image_sets'

# Collect all image paths
all_images = []
for class_folder in os.listdir(base_path):
    class_path = os.path.join(base_path, class_folder)
    if os.path.isdir(class_path):
        images = [os.path.join(class_path, img) for img in os.listdir(class_path)]
        all_images.extend(images)

# Randomly select 5 images
sample_images = random.sample(all_images, 5)

# Display the images
plt.figure(figsize=(10, 5))
for i, img_path in enumerate(sample_images):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.subplot(1, 5, i+1)
    plt.imshow(img)
    plt.axis('off')
    plt.title("Random Image")
plt.tight_layout()
plt.show()

print("Selected Image Paths:", sample_images)

"""Predictions"""

import numpy as np

def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (224, 224))  # Adjust if your model uses a different size
    img = img / 255.0  # Normalize
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    return img

def predict_image(image_path):
    img = preprocess_image(image_path)
    prediction = model.predict(img)
    class_names = ['Normal', 'Adenocarcinoma', 'Squamous Cell Carcinoma']
    predicted_class = class_names[np.argmax(prediction)]
    confidence = np.max(prediction) * 100
    print(f"Prediction: {predicted_class} with {confidence:.2f}% confidence.")


# Perform predictions on the selected random images
for img_path in sample_images:
    predict_image(img_path)

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Get true labels
y_true = val_generator.classes

# Predict on the validation set
y_pred = np.argmax(model.predict(val_generator), axis=1)

# Class names
class_names = ['Normal', 'Adenocarcinoma', 'Squamous Cell Carcinoma']

print("Prediction Complete.")

# Create confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Plot using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()



